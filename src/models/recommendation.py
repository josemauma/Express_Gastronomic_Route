import os
import json
from openai import OpenAI
from dotenv import load_dotenv
import streamlit as st

# â”€â”€â”€ ConfiguraciÃ³n de pÃ¡gina â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="Perfiles GastronÃ³micos para tu TFM",
    layout="wide",
    initial_sidebar_state="expanded"
)

# â”€â”€â”€ Carga de credenciales â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.sidebar.error("ğŸ”‘ Introduce tu OPENAI_API_KEY en el .env")
    st.stop()

llm_client = OpenAI(api_key=OPENAI_API_KEY)
MODEL = "gpt-4o-mini-2024-07-18"

SYSTEM_PROMPT = {
    "role": "system",
    "content": """
Eres un crÃ­tico gastronÃ³mico profesional con humor Ã¡gil e inteligente.
A partir de la informaciÃ³n que el usuario proporcione sobre un restaurante,
genera una salida estructurada en cuatro bloques claros:

1. DescripciÃ³n breve (3â€“4 frases).  
2. Mejores platos (3 Ã­tems, nombre + motivo de su Ã©xito).  
3. Comentarios positivos de clientes (3 reseÃ±as ficticias, 1â€“2 frases cada una).  
4. JustificaciÃ³n de elecciÃ³n para un TFM sobre innovaciÃ³n y sostenibilidad (2â€“3 frases).

Siempre responde en espaÃ±ol.
"""
}

# â”€â”€â”€ Carga de datos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with open("/Users/josemanuelmuelas/Desktop/Express_Gastronomic_Route/restaurants.json", encoding="utf-8") as f:
    restaurantes = json.load(f)

# â”€â”€â”€ Sidebar de informaciÃ³n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.title("âš™ï¸ Ajustes")
st.sidebar.write("AquÃ­ podrÃ¡s ver los restaurantes cargados y tu API Key.")

for r in restaurantes:
    st.sidebar.markdown(f"**{r['nombre']}**")  
st.sidebar.caption("Todos los datos salen de `restaurants.json`")

# â”€â”€â”€ TÃ­tulo principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ½ï¸ Perfiles GastronÃ³micos para tu TFM")

st.markdown(
    "Pulsa el botÃ³n y genera de una vez los perfiles **El Pimpi** y **La Tranca**, "
    "listos para copiar en tu trabajo fin de mÃ¡ster."
)

# â”€â”€â”€ BotÃ³n Ãºnico para generar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.button("ğŸš€ Generar todos los perfiles"):

    # Creamos dos columnas para mostrar resultado de ambos
    col1, col2 = st.columns(2)

    for idx, resto in enumerate(restaurantes):
        user_msg = {
            "role": "user",
            "content": json.dumps(resto, ensure_ascii=False)
        }
        # Llamada al LLM
        response = llm_client.chat.completions.create(
            model=MODEL,
            messages=[SYSTEM_PROMPT, user_msg],
            temperature=0.7,
            max_tokens=600
        ).choices[0].message.content

        # Mostramos en la columna correspondiente
        with (col1 if idx == 0 else col2):
            st.markdown(f"### {resto['nombre']}")
            st.markdown(response)

else:
    st.info("Haz clic en **Generar todos los perfiles** para comenzar.")

